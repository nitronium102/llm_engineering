{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "## ğŸ¯ ë‹¨ê³„ë³„ ì ‘ê·¼ ê°€ì´ë“œ\n",
    "\n",
    "### 1ë‹¨ê³„: ê¸°ë³¸ êµ¬ì¡° ì„¤ì • (í•„ìˆ˜)\n",
    "- [ ] Imports (ollama, gradio)\n",
    "- [ ] ëª¨ë¸ ì„¤ì • ë° Ollama í™•ì¸\n",
    "- [ ] System prompt ì‘ì„± (ê¸°ìˆ  íŠœí„° ì—­í• )\n",
    "\n",
    "### 2ë‹¨ê³„: ê¸°ë³¸ Chat í•¨ìˆ˜ (í•„ìˆ˜)\n",
    "- [ ] Gradio ChatInterfaceë¡œ ê°„ë‹¨í•œ ì±„íŒ… êµ¬í˜„\n",
    "- [ ] History ê´€ë¦¬\n",
    "- [ ] System prompt ì ìš©\n",
    "\n",
    "### 3ë‹¨ê³„: ìŠ¤íŠ¸ë¦¬ë° ì¶”ê°€ (í•„ìˆ˜)\n",
    "- [ ] `ollama.chat(..., stream=True)` ì‚¬ìš©\n",
    "- [ ] Generator í•¨ìˆ˜ë¡œ `yield` ì‚¬ìš©\n",
    "- [ ] ì‹¤ì‹œê°„ ì‘ë‹µ í‘œì‹œ í™•ì¸\n",
    "\n",
    "### 4ë‹¨ê³„: ëª¨ë¸ ì „í™˜ ê¸°ëŠ¥ (í•„ìˆ˜)\n",
    "- [ ] `gr.Dropdown`ìœ¼ë¡œ ëª¨ë¸ ì„ íƒ UI ì¶”ê°€\n",
    "- [ ] `additional_inputs`ì— ë“œë¡­ë‹¤ìš´ ì—°ê²°\n",
    "- [ ] Chat í•¨ìˆ˜ì—ì„œ ëª¨ë¸ ì„ íƒ ë°˜ì˜\n",
    "\n",
    "### 5ë‹¨ê³„: Tool ì¶”ê°€ (ë³´ë„ˆìŠ¤)\n",
    "- [ ] Tool í•¨ìˆ˜ ì •ì˜ (ì˜ˆ: ì½”ë“œ ê²€ìƒ‰, ë¬¸ì„œ ê²€ìƒ‰)\n",
    "- [ ] Tool schema ì •ì˜\n",
    "- [ ] `handle_tool_calls` í•¨ìˆ˜ êµ¬í˜„\n",
    "- [ ] Tool í˜¸ì¶œ ë£¨í”„ ì²˜ë¦¬\n",
    "\n",
    "### 6ë‹¨ê³„: ê³ ê¸‰ ê¸°ëŠ¥ (ì„ íƒ)\n",
    "- [ ] ì˜¤ë””ì˜¤ ì…ë ¥/ì¶œë ¥\n",
    "- [ ] ì˜ˆì‹œ ì§ˆë¬¸ ì¶”ê°€\n",
    "- [ ] UI ì»¤ìŠ¤í„°ë§ˆì´ì§•\n",
    "\n",
    "## ğŸ’¡ êµ¬í˜„ íŒ\n",
    "\n",
    "1. **ì‘ì€ ê²ƒë¶€í„° ì‹œì‘**: ë¨¼ì € ê¸°ë³¸ ì±„íŒ…ë§Œ êµ¬í˜„í•˜ê³ , í•˜ë‚˜ì”© ê¸°ëŠ¥ ì¶”ê°€\n",
    "2. **Week 1 Exercise ì°¸ê³ **: ì´ë¯¸ ë§Œë“  ì½”ë“œë¥¼ ì¬ì‚¬ìš©í•˜ì„¸ìš”\n",
    "3. **Week 2 Day 3-5 ì°¸ê³ **: Gradio, ìŠ¤íŠ¸ë¦¬ë°, Tool ì˜ˆì œê°€ ìˆìŠµë‹ˆë‹¤\n",
    "4. **ì—ëŸ¬ ì²˜ë¦¬**: try-exceptë¡œ Ollama ì—°ê²° í™•ì¸\n",
    "5. **í…ŒìŠ¤íŠ¸**: ê° ë‹¨ê³„ë§ˆë‹¤ í…ŒìŠ¤íŠ¸í•˜ë©° ì§„í–‰\n",
    "\n",
    "## ğŸ“š ì°¸ê³ í•  íŒŒì¼ë“¤\n",
    "\n",
    "- `week1/week1 EXERCISE.ipynb` - ê¸°ë³¸ êµ¬ì¡° ì°¸ê³ \n",
    "- `week2/day3.ipynb` - Gradio ChatInterface ì˜ˆì œ\n",
    "- `week2/day4.ipynb` - Tool calling ì˜ˆì œ\n",
    "- `week2/day5.ipynb` - ì™„ì „í•œ ì˜ˆì œ\n",
    "\n",
    "## Example Solution\n",
    "\n",
    "ì•„ë˜ëŠ” ì™„ì „í•œ ì˜ˆì‹œ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. ë¨¼ì € ì§ì ‘ êµ¬í˜„í•´ë³´ê³ , ë§‰íˆë©´ ì°¸ê³ í•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed6a08",
   "metadata": {},
   "source": [
    "## ğŸš€ ì‹œì‘í•˜ê¸° ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "ì•„ë˜ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ êµ¬í˜„í•´ë³´ì„¸ìš”. ê° ì…€ì€ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ìš”êµ¬ì‚¬í•­:**\n",
    "1. âœ… Gradio UI (ChatInterface ì‚¬ìš©)\n",
    "2. âœ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ\n",
    "3. âœ… System promptë¡œ ì „ë¬¸ì„± ì¶”ê°€\n",
    "4. âœ… ëª¨ë¸ ì „í™˜ ê¸°ëŠ¥\n",
    "5. ğŸ ë³´ë„ˆìŠ¤: Tool ì‚¬ìš©\n",
    "\n",
    "**ì‹œì‘ ì „ í™•ì¸:**\n",
    "- [ ] Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ê°€ìš”? (`ollama list`ë¡œ í™•ì¸)\n",
    "- [ ] ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆë‚˜ìš”? (`ollama pull llama3.2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c76d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Ollama is available\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"llama3.2\"\n",
    "\n",
    "try:\n",
    "    ollama.list()\n",
    "    print(\"âœ“ Ollama is available\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Ollama may not be running: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f588217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt - ì „ë¬¸ì„± ì¶”ê°€\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful technical tutor who answers questions about Python code, \n",
    "software engineering, machine learning, and LLMs.\n",
    "\n",
    "You are a senior software engineer with 20 years of experience in the field.\n",
    "You are also an expert in teaching and explaining complex ideas.\n",
    "\n",
    "When answering questions:\n",
    "- Provide precise and detailed explanations\n",
    "- Use examples when helpful\n",
    "- Break down complex concepts into understandable parts\n",
    "- If you don't know something, say so honestly\n",
    "\n",
    "Always be accurate and helpful.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97bef90",
   "metadata": {},
   "source": [
    "### Add Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da31fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "def search_code_examples(topic: str) -> str:\n",
    "    examples_db = {\n",
    "        \"generator\": \"def my_generator():\\n    yield 1\\n    yield 2\\n    yield 3\",\n",
    "        \"decorator\": \"@my_decorator\\ndef my_function():\\n    pass\",\n",
    "        \"context manager\": \"with open('file.txt') as f:\\n    content = f.read()\",\n",
    "        \"list comprehension\": \"[x**2 for x in range(10) if x % 2 == 0]\",\n",
    "        \"async\": \"async def fetch_data():\\n    async with aiohttp.ClientSession() as session:\\n        async with session.get(url) as response:\\n            return await response.json()\"\n",
    "    }\n",
    "    topic_lower = topic.lower()\n",
    "    for key, example in examples_db.items():\n",
    "        if key in topic_lower:\n",
    "            return f\"Code example for '{key}':\\n```python\\n{example}\\n```\"\n",
    "    \n",
    "    return f\"No code example found for '{topic}'. Available topics: {', '.join(examples_db.keys())}\"\n",
    "\n",
    "# Tool definition\n",
    "code_search_function = {\n",
    "    \"name\": \"search_code_examples\",\n",
    "    \"description\": \"Search for Python code examples by topic (e.g., generator, decorator, async, list comprehension)\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"topic\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The programming topic or concept to search for code examples\"\n",
    "            }            \n",
    "        },\n",
    "        \"required\": [\"topic\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af8267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_python_docs(concept: str) -> str:\n",
    "    \"\"\"Python ê°œë…ì— ëŒ€í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬\"\"\"\n",
    "    docs_db = {\n",
    "        \"yield\": \"The 'yield' keyword is used to create a generator function. It pauses function execution and returns a value to the caller, but retains enough state to enable the function to resume where it left off.\",\n",
    "        \"decorator\": \"A decorator is a design pattern in Python that allows a user to add new functionality to an existing object without modifying its structure.\",\n",
    "        \"async\": \"Async/await syntax allows you to write asynchronous code that looks like synchronous code, making it easier to handle concurrent operations.\"\n",
    "    }\n",
    "    \n",
    "    concept_lower = concept.lower()\n",
    "    for key, doc in docs_db.items():\n",
    "        if key in concept_lower:\n",
    "            return f\"Documentation for '{key}':\\n{doc}\"\n",
    "    \n",
    "    return f\"No documentation found for '{concept}'. Available concepts: {', '.join(docs_db.keys())}\"\n",
    "\n",
    "docs_search_function = {\n",
    "    \"name\": \"get_python_docs\",\n",
    "    \"description\": \"Get documentation or explanation for a Python concept (e.g., yield, decorator, async)\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"concept\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The Python concept to get documentation for\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"concept\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b9a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools defined:\n",
      "- search_code_examples: Search for Python code examples\n",
      "- get_python_docs: Get Python documentation\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": code_search_function},\n",
    "    {\"type\": \"function\", \"function\": docs_search_function}\n",
    "]\n",
    "\n",
    "print(\"Tools defined:\")\n",
    "print(\"- search_code_examples: Search for Python code examples\")\n",
    "print(\"- get_python_docs: Get Python documentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ab8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(message):\n",
    "    responses = []\n",
    "\n",
    "    if not message.get(\"tool_calls\"):\n",
    "        return responses\n",
    "\n",
    "    for tool_call in message[\"tool_calls\"]:\n",
    "        tool_name = tool_call[\"function\"][\"name\"]\n",
    "        arguments = tool_call[\"function\"].get(\"arguments\", {})\n",
    "\n",
    "        if isinstance(arguments, str):\n",
    "            try:\n",
    "                arguments = json.loads(arguments)\n",
    "            except json.JSONDecodeError:\n",
    "                arguments = {}\n",
    "        \n",
    "        elif not isinstance(arguments, dict):\n",
    "            arguments = {}\n",
    "\n",
    "        # Tool call ID ì¶”ì¶œ (ì„ íƒì )\n",
    "        tool_call_id = tool_call.get('id')\n",
    "\n",
    "        if tool_name == \"search_code_examples\":\n",
    "            topic = arguments.get(\"topic\", \"\")\n",
    "            result = search_code_examples(topic)\n",
    "\n",
    "        elif tool_name == \"get_python_docs\":\n",
    "            concept = arguments.get(\"concept\", \"\")\n",
    "            result = get_python_docs(concept)\n",
    "\n",
    "        else:\n",
    "            result = f\"Unknown tool: {tool_name}\"\n",
    "\n",
    "        response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": result # Tool ì‹¤í–‰ ê²°ê³¼\n",
    "        }\n",
    "\n",
    "        if tool_call_id:\n",
    "            response[\"tool_call_id\"] = tool_call_id\n",
    "\n",
    "        responses.append(response)\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e68e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tool í˜¸ì¶œ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# def handle_tool_calls(message):\n",
    "#     \"\"\"\n",
    "#     LLMì´ í˜¸ì¶œí•œ Toolë“¤ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "#     ì´ í•¨ìˆ˜ëŠ” LLMì˜ ì‘ë‹µ ë©”ì‹œì§€ì—ì„œ tool_callsë¥¼ ì¶”ì¶œí•˜ì—¬,\n",
    "#     ê° toolì„ ì‹¤í–‰í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "#     Args:\n",
    "#         message (dict): LLMì˜ ì‘ë‹µ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬\n",
    "#                        ì˜ˆ: {\n",
    "#                            \"role\": \"assistant\",\n",
    "#                            \"content\": \"...\",\n",
    "#                            \"tool_calls\": [\n",
    "#                                {\n",
    "#                                    \"function\": {\"name\": \"get_python_docs\", \"arguments\": {...}},\n",
    "#                                    \"id\": \"call_123\"\n",
    "#                                }\n",
    "#                            ]\n",
    "#                        }\n",
    "    \n",
    "#     Returns:\n",
    "#         list: Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ ë‹´ì€ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸\n",
    "#               ê° ìš”ì†ŒëŠ” {\"role\": \"tool\", \"content\": \"...\", \"tool_call_id\": \"...\"} í˜•ì‹\n",
    "    \n",
    "#     ë™ì‘ íë¦„:\n",
    "#     1. messageì—ì„œ tool_callsê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "#     2. ê° tool_callì„ ìˆœíšŒí•˜ë©°:\n",
    "#        - Tool ì´ë¦„ ì¶”ì¶œ\n",
    "#        - Arguments íŒŒì‹± (ë¬¸ìì—´ì´ë©´ JSON íŒŒì‹±)\n",
    "#        - í•´ë‹¹ Tool í•¨ìˆ˜ ì‹¤í–‰\n",
    "#        - ê²°ê³¼ë¥¼ tool ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "#     3. ëª¨ë“  ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "#     \"\"\"\n",
    "#     # ğŸ“¦ Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "#     # ê° toolì˜ ì‹¤í–‰ ê²°ê³¼ê°€ ì´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë©ë‹ˆë‹¤\n",
    "#     responses = []\n",
    "    \n",
    "#     # ğŸ” Tool í˜¸ì¶œì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "#     # message.get('tool_calls')ëŠ” tool_calls í‚¤ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜\n",
    "#     # tool_callsê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ë¹ ë¥¸ ì¢…ë£Œ)\n",
    "#     if not message.get('tool_calls'):\n",
    "#         return responses\n",
    "    \n",
    "#     # ğŸ”„ ê° tool_callì„ ìˆœíšŒí•˜ë©° ì²˜ë¦¬\n",
    "#     # LLMì´ ì—¬ëŸ¬ toolì„ ë™ì‹œì— í˜¸ì¶œí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°˜ë³µë¬¸ ì‚¬ìš©\n",
    "#     for tool_call in message['tool_calls']:\n",
    "#         # ğŸ“› Tool ì´ë¦„ ì¶”ì¶œ\n",
    "#         # tool_call['function']['name']ì—ì„œ í˜¸ì¶œí•˜ë ¤ëŠ” í•¨ìˆ˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°\n",
    "#         # ì˜ˆ: \"get_python_docs\", \"search_code_examples\"\n",
    "#         tool_name = tool_call['function']['name']\n",
    "        \n",
    "#         # ğŸ”§ Arguments íŒŒì‹± (ë§¤ìš° ì¤‘ìš”!)\n",
    "#         # LLMì´ ì „ë‹¬í•œ ì¸ìë“¤ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±í•©ë‹ˆë‹¤\n",
    "#         # OllamaëŠ” argumentsë¥¼ ë¬¸ìì—´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "        \n",
    "#         # ê¸°ë³¸ê°’ìœ¼ë¡œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì„¤ì •\n",
    "#         arguments = tool_call['function'].get('arguments', {})\n",
    "        \n",
    "#         # Case 1: argumentsê°€ ë¬¸ìì—´ì¸ ê²½ìš° (JSON ë¬¸ìì—´)\n",
    "#         # ì˜ˆ: '{\"concept\": \"yield\"}' -> {\"concept\": \"yield\"}\n",
    "#         if isinstance(arguments, str):\n",
    "#             try:\n",
    "#                 # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±\n",
    "#                 arguments = json.loads(arguments)\n",
    "#             except json.JSONDecodeError:\n",
    "#                 # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì„¤ì • (ì—ëŸ¬ ë°©ì§€)\n",
    "#                 arguments = {}\n",
    "        \n",
    "#         # Case 2: argumentsê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš°\n",
    "#         # ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì…ì´ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì„¤ì •\n",
    "#         elif not isinstance(arguments, dict):\n",
    "#             arguments = {}\n",
    "        \n",
    "#         # ğŸ†” Tool call ID ì¶”ì¶œ (ì„ íƒì )\n",
    "#         # ê° tool í˜¸ì¶œì„ ì¶”ì í•˜ê¸° ìœ„í•œ ê³ ìœ  ID\n",
    "#         # ì¼ë¶€ ëª¨ë¸ì€ ì´ IDë¥¼ ì œê³µí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\n",
    "#         tool_call_id = tool_call.get('id')\n",
    "        \n",
    "#         # ğŸ› ï¸ Tool ì‹¤í–‰\n",
    "#         # tool_nameì— ë”°ë¼ ì ì ˆí•œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤\n",
    "#         if tool_name == \"search_code_examples\":\n",
    "#             # ì½”ë“œ ì˜ˆì‹œ ê²€ìƒ‰ tool í˜¸ì¶œ\n",
    "#             topic = arguments.get('topic', '')  # 'topic' í‚¤ì—ì„œ ê°’ ì¶”ì¶œ, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´\n",
    "#             result = search_code_examples(topic)  # ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰\n",
    "        \n",
    "#         elif tool_name == \"get_python_docs\":\n",
    "#             # Python ë¬¸ì„œ ê²€ìƒ‰ tool í˜¸ì¶œ\n",
    "#             concept = arguments.get('concept', '')  # 'concept' í‚¤ì—ì„œ ê°’ ì¶”ì¶œ, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´\n",
    "#             result = get_python_docs(concept)  # ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰\n",
    "        \n",
    "#         else:\n",
    "#             # ì•Œ ìˆ˜ ì—†ëŠ” toolì¸ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜\n",
    "#             result = f\"Unknown tool: {tool_name}\"\n",
    "        \n",
    "#         # ğŸ“¤ Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "#         # LLMì€ \"role\": \"tool\"ì¸ ë©”ì‹œì§€ë¥¼ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤\n",
    "#         response = {\n",
    "#             \"role\": \"tool\",  # Tool ì‘ë‹µì„ì„ ë‚˜íƒ€ë‚´ëŠ” ì—­í• \n",
    "#             \"content\": result  # Tool ì‹¤í–‰ ê²°ê³¼\n",
    "#         }\n",
    "        \n",
    "#         # Tool call IDê°€ ìˆìœ¼ë©´ ì¶”ê°€\n",
    "#         # LLMì´ ì—¬ëŸ¬ toolì„ í˜¸ì¶œí–ˆì„ ë•Œ ì–´ë–¤ toolì˜ ê²°ê³¼ì¸ì§€ êµ¬ë¶„í•˜ê¸° ìœ„í•¨\n",
    "#         if tool_call_id:\n",
    "#             response[\"tool_call_id\"] = tool_call_id\n",
    "        \n",
    "#         # ğŸ“‹ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "#         # ì—¬ëŸ¬ toolì´ í˜¸ì¶œë˜ì—ˆì„ ê²½ìš° ëª¨ë“  ê²°ê³¼ë¥¼ ìˆ˜ì§‘\n",
    "#         responses.append(response)\n",
    "    \n",
    "#     # âœ… ëª¨ë“  tool ì‹¤í–‰ ê²°ê³¼ ë°˜í™˜\n",
    "#     # ì´ ë¦¬ìŠ¤íŠ¸ëŠ” chat í•¨ìˆ˜ì—ì„œ messagesì— ì¶”ê°€ë˜ì–´ LLMì—ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤\n",
    "#     return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a513df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history, model_choice=None):\n",
    "    # ëª¨ë¸ ì„ íƒ (model_choiceê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)\n",
    "    model = model_choice if model_choice else MODEL\n",
    "    \n",
    "    # historyë¥¼ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    # ì´ì „ ëŒ€í™”ë“¤ ì¶”ê°€\n",
    "    for h in history:\n",
    "        messages.append({\"role\": h[\"role\"], \"content\": h[\"content\"]})\n",
    "    # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    while True: \n",
    "        stream = ollama.chat(model=model, messages=messages, tools=tools, stream=True)\n",
    "\n",
    "        # streamling ì‘ë‹µ ìˆ˜ì§‘\n",
    "        response_text = \"\"\n",
    "        assistant_message = None\n",
    "\n",
    "        # stream\n",
    "        for chunk in stream:\n",
    "            if chunk.get('message'):\n",
    "                msg = chunk['message']\n",
    "                if msg.get('content'):\n",
    "                    response_text += msg['content']\n",
    "                    yield response_text\n",
    "                \n",
    "                # tool callsê°€ ìˆìœ¼ë©´ ë©”ì‹œì§€ ì €ì¥\n",
    "                if msg.get('tool_calls') and not assistant_message:\n",
    "                    assistant_message = msg.copy()\n",
    "                    if response_text:\n",
    "                        assistant_message['content'] = response_text\n",
    "\n",
    "        if not assistant_message or not assistant_message.get('tool_calls'):\n",
    "            break\n",
    "        \n",
    "        # tool calls ì²˜ë¦¬\n",
    "        tool_responses = handle_tool_calls(assistant_message)\n",
    "\n",
    "        # assistant ë©”ì‹œì§€ì™€ tool ì‘ë‹µì„ ë©”ì‹œì§€ì— ì¶”ê°€\n",
    "        messages.append(assistant_message)\n",
    "        messages.extend(tool_responses)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3332e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ë©”ì¸ Chat í•¨ìˆ˜ - ìŠ¤íŠ¸ë¦¬ë°, ëª¨ë¸ ì „í™˜, Tool ì§€ì›\n",
    "\n",
    "# def chat(message, history, model_choice):\n",
    "#     \"\"\"\n",
    "#     ë©”ì¸ ì±„íŒ… í•¨ìˆ˜\n",
    "#     - ìŠ¤íŠ¸ë¦¬ë° ì§€ì›\n",
    "#     - ëª¨ë¸ ì „í™˜ ì§€ì›\n",
    "#     - Tool í˜¸ì¶œ ì§€ì›\n",
    "#     \"\"\"\n",
    "#     # ëª¨ë¸ ì„ íƒ\n",
    "#     model = AVAILABLE_MODELS.get(model_choice, DEFAULT_MODEL)\n",
    "    \n",
    "#     # Historyë¥¼ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "#     messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "#     # ì´ì „ ëŒ€í™” ì¶”ê°€\n",
    "#     for h in history:\n",
    "#         messages.append({\"role\": h[\"role\"], \"content\": h[\"content\"]})\n",
    "    \n",
    "#     # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "#     messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "#     # Tool í˜¸ì¶œ ì²˜ë¦¬ ë£¨í”„\n",
    "#     while True:\n",
    "#         # ì‘ë‹µ ê°€ì ¸ì˜¤ê¸° (ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ)\n",
    "#         stream = ollama.chat(model=model, messages=messages, tools=tools, stream=True)\n",
    "        \n",
    "#         # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìˆ˜ì§‘\n",
    "#         response_text = \"\"\n",
    "#         assistant_message = None\n",
    "        \n",
    "#         for chunk in stream:\n",
    "#             if chunk.get('message'):\n",
    "#                 msg = chunk['message']\n",
    "#                 if msg.get('content'):\n",
    "#                     response_text += msg['content']\n",
    "#                     yield response_text\n",
    "                \n",
    "#                 # Tool callsê°€ ìˆìœ¼ë©´ ë©”ì‹œì§€ ì €ì¥\n",
    "#                 if msg.get('tool_calls') and not assistant_message:\n",
    "#                     assistant_message = msg.copy()\n",
    "#                     if response_text:\n",
    "#                         assistant_message['content'] = response_text\n",
    "        \n",
    "#         # Tool í˜¸ì¶œì´ ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
    "#         if not assistant_message or not assistant_message.get('tool_calls'):\n",
    "#             break\n",
    "        \n",
    "#         # Tool í˜¸ì¶œ ì²˜ë¦¬\n",
    "#         tool_responses = handle_tool_calls(assistant_message)\n",
    "        \n",
    "#         # Assistant ë©”ì‹œì§€ì™€ tool ì‘ë‹µì„ ë©”ì‹œì§€ì— ì¶”ê°€\n",
    "#         messages.append(assistant_message)\n",
    "#         messages.extend(tool_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f432811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7888\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7888/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio UI ìƒì„±\n",
    "\n",
    "# ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´ (ëª¨ë¸ ì „í™˜ ê¸°ëŠ¥ ì‚¬ìš© ì‹œ)\n",
    "model_dropdown = gr.Dropdown(\n",
    "    choices=[\"llama3.2\", \"llama3.1\", \"qwen2.5\", \"mistral\"],\n",
    "    value=\"llama3.2\",\n",
    "    label=\"Select Model\",\n",
    "    info=\"Choose which Ollama model to use\"\n",
    ")\n",
    "\n",
    "# ChatInterface ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)\n",
    "chat_interface = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    type=\"messages\",\n",
    "    title=\"ğŸ¤– Technical Q&A Assistant\",\n",
    "    description=\"\"\"\n",
    "    Ask technical questions about Python, software engineering, ML, and LLMs!\n",
    "    \n",
    "    Features:\n",
    "    - âœ¨ Streaming responses\n",
    "    - ğŸ”„ Model switching\n",
    "    - ğŸ› ï¸ Tool support (code examples, documentation)\n",
    "    - ğŸ’¡ Expert explanations\n",
    "    \n",
    "    Try asking:\n",
    "    - \"Explain generators in Python\"\n",
    "    - \"What is a decorator?\"\n",
    "    - \"Show me an async example\"\n",
    "    \"\"\",\n",
    "    additional_inputs=[model_dropdown],  # ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´ ì¶”ê°€\n",
    "    examples=[\n",
    "        # additional_inputsë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ê° ì˜ˆì‹œê°€ [message, model_choice] í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "        [\"Explain what this code does: yield from {x for x in range(10)}\", \"llama3.2\"],\n",
    "        [\"What is a Python decorator?\", \"llama3.2\"],\n",
    "        [\"Show me an example of async/await\", \"llama3.2\"],\n",
    "        [\"Explain list comprehensions\", \"llama3.2\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_interface.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e2803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
